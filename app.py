import streamlit as st
import pandas as pd
import plotly.express as px
import os
import snowflake.connector
from dotenv import load_dotenv

# Load env variables (for local dev)
load_dotenv()

st.set_page_config(
    page_title="Enterprise Data Quality Monitor",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS Styling ---
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        border-right: 5px solid #4e8cff;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .metric-value {
        font-size: 2rem;
        font-weight: bold;
        color: #0e1117;
    }
    .metric-label {
        font-size: 1rem;
        color: #555;
    }
</style>
""", unsafe_allow_html=True)

# --- Helper Functions ---

# @st.cache_data (Disabled by user request)
def load_demo_data():
    """Loads static CSV for Demo Mode"""
    try:
        # Assuming dashboard_feed.csv is generated by snapshot_generator.py
        # and placed in the root or accessible path
        return pd.read_csv("dashboard_feed.csv")
    except FileNotFoundError:
        st.error("Demo data not found. Please run snapshot_generator.py first.")
        return pd.DataFrame()

def get_snowflake_connection():    
    # 1. Load Secrets (Safely)
    secrets = {}
    if os.path.exists(".streamlit/secrets.toml"):
        try:
            secrets = st.secrets
        except:
            pass

    # 2. Helper to get config (Priority: Secrets > Env)
    def get_config(key):
        return secrets.get(key) or os.getenv(key)

    # 3. Connect
    return snowflake.connector.connect(
        account   = get_config("SNOWFLAKE_ACCOUNT"),
        user      = get_config("SNOWFLAKE_USER"),
        password  = get_config("SNOWFLAKE_PASSWORD"),
        role      = get_config("SNOWFLAKE_ROLE"),
        warehouse = get_config("SNOWFLAKE_WAREHOUSE"),
        database  = get_config("SNOWFLAKE_DATABASE"),
        schema    = "RAW_MARTS"
    )

def fetch_live_data(conn):
    """Queries Snowflake for real-time data"""
    query = """
    SELECT 
        order_date, 
        status, 
        count(*) as order_count, 
        sum(total_amount) as total_revenue,
        
        -- Clean Revenue (Excluding all known bad data)
        sum(case 
            when is_orphan_order 
              or has_negative_amount 
              or has_math_error 
              or is_future_order 
              or has_bad_status 
              or is_duplicate 
            then 0 
            else total_amount 
        end) as clean_revenue,

        count(case when is_orphan_order then 1 end) as orphan_orders,
        count(case when has_negative_amount then 1 end) as negative_amount_orders,
        count(case when is_duplicate then 1 end) as duplicate_orders,
        count(case when is_future_order then 1 end) as future_orders,
        count(case when has_math_error then 1 end) as math_errors,
        count(case when has_bad_status then 1 end) as bad_status_orders
    FROM RAW_MARTS.FCT_ORDERS
    GROUP BY 1, 2
    """
    return pd.read_sql(query, conn)

# --- Main App ---

def main():
    st.title("ðŸ›¡ï¸ Enterprise Data Quality Monitor")
    st.markdown("### Hybrid Architecture: ELT + Observability")

    # --- Sidebar ---
    st.sidebar.header("Configuration")
    mode = st.sidebar.radio("Data Source Mode", ["Demo (Static Snapshot)", "Live (Snowflake)"])
    
    st.sidebar.markdown("---")
    st.sidebar.info(f"Current Mode: **{mode}**")
    
    df = pd.DataFrame()
    
    # --- Data Loading Logic ---
    if mode == "Demo (Static Snapshot)":
        df = load_demo_data()
        if df.empty:
            st.warning("No Demo Data available.")
    else:
        # Live Mode
        with st.spinner("Connecting to Snowflake..."):
            try:
                conn = get_snowflake_connection()
                df = fetch_live_data(conn)
                st.toast("Connected to Snowflake Live!", icon="ðŸŸ¢")
            except Exception as e:
                st.error(f"Connection Failed: {e}")
                st.warning("âš ï¸ Falling back to Demo Mode...")
                df = load_demo_data()

    if df.empty:
        return

    # Normalize columns to lowercase
    df.columns = df.columns.str.lower()

    # --- Transformation for Dashboard (Aggregations) ---
    # Convert date
    if 'order_date' in df.columns:
        df['order_date'] = pd.to_datetime(df['order_date'])
    
    # Calculate KPIs
    total_orders = df['order_count'].sum()
    total_revenue = df['total_revenue'].sum()
    total_orphan = df['orphan_orders'].sum()
    total_negative = df['negative_amount_orders'].sum()
    total_duplicate = df['duplicate_orders'].sum() if 'duplicate_orders' in df.columns else 0
    total_future = df['future_orders'].sum() if 'future_orders' in df.columns else 0
    total_math = df['math_errors'].sum() if 'math_errors' in df.columns else 0
    total_bad_status = df['bad_status_orders'].sum() if 'bad_status_orders' in df.columns else 0
    
    dq_issue_count = (total_orphan + total_negative + total_duplicate + 
                      total_future + total_math + total_bad_status)
    dq_score = max(0, 100 - (dq_issue_count / total_orders * 100)) if total_orders > 0 else 100

    # --- Dashboard Layout ---
    
    # Row 1: KPIs
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Data Health Score", f"{dq_score:.1f}%", delta=f"-{100-dq_score:.1f}%" if dq_score < 100 else "0%", delta_color="inverse")
    with col2:
        st.metric("Total Revenue", f"${total_revenue:,.2f}")
    with col3:
        st.metric("Total Orders", f"{total_orders:,}")
    with col4:
        st.metric("Quality Incidents", f"{dq_issue_count}", delta="High Severity" if dq_issue_count > 0 else "Clean", delta_color="inverse")

    st.markdown("---")
    
    # Tabs
    tab1, tab2 = st.tabs(["ðŸ“Š Business Overview", "ðŸš¨ Quarantine Zone"])
    
    with tab1:
        # Time Series
        # Time Series
        if not df.empty:
            # Filter out future dates (Chaos Data) for the cleaner Business View
            valid_dates_mask = df['order_date'] <= pd.Timestamp.now()
            df_clean_view = df[valid_dates_mask]
            
            # Group by date for the Chart
            daily = df_clean_view.groupby('order_date')[['total_revenue', 'clean_revenue']].sum().reset_index()
            
            # Melt for multi-line chart
            daily_melted = daily.melt(id_vars='order_date', value_vars=['total_revenue', 'clean_revenue'], 
                                      var_name='Metric', value_name='Amount')
            
            fig = px.line(daily_melted, x='order_date', y='Amount', color='Metric',
                          title='ðŸ’° Revenue Quality Impact: Reported (Raw) vs Real (Clean)',
                          color_discrete_map={'total_revenue': 'red', 'clean_revenue': 'green'},
                          markers=True)
                          
            st.plotly_chart(fig, width="stretch")
            
            # Calculation of "Lost/Risk Revenue"
            total_raw = daily['total_revenue'].sum()
            total_clean = daily['clean_revenue'].sum()
            delta_risk = total_raw - total_clean
            
            st.warning(f"âš ï¸ Financial Risk Detected: ${delta_risk:,.2f} of reported revenue is compromised by data quality issues.")
            
            # Status Distribution
            # Chaos Monkey introduces many dirty statuses ("Completado", "Shipped!").
            # Clean charts should group these into "Invalid" or filter them.
            VALID_STATUSES = ['COMPLETED', 'PENDING', 'SHIPPED', 'CANCELLED']
            
            df_status_clean = df.copy()
            df_status_clean['status_group'] = df_status_clean['status'].apply(
                lambda x: x if x in VALID_STATUSES else 'INVALID/DIRTY'
            )
            
            status_df = df_status_clean.groupby('status_group')['order_count'].sum().reset_index()
            fig2 = px.bar(status_df, x='status_group', y='order_count', 
                          title='Orders by Status (Dirty Data Grouped)', 
                          color='status_group',
                          color_discrete_map={'INVALID/DIRTY': 'red', 'COMPLETED': 'green', 'PENDING': 'orange'})
            st.plotly_chart(fig2, width="stretch")

    with tab2:
        st.subheader("Data Quality Issues Detected")
        st.markdown("Rows flagged by **Elementary** & **dbt** tests.")
        
        
        # Breakdown
        dq_data = pd.DataFrame({
            'Issue Type': [
                'Orphan Orders (FK Failure)', 
                'Negative Amounts (Domain Error)', 
                'Duplicate Orders (Uniqueness)',
                'Future Dates (Temporal Validity)',
                'Math Mismatch (Calculation Integrity)',
                'Invalid Status (String Inconsistency)'
            ],
            'Count': [
                total_orphan, 
                total_negative, 
                total_duplicate,
                total_future,
                total_math,
                total_bad_status
            ],
            'Impact': ['High', 'High', 'Critical', 'Medium', 'Medium', 'Low']
        })
        st.table(dq_data)
        
        if dq_issue_count > 0:
            st.markdown("#### Drill Down (Simulated Detail)")
            # In a real app we would query the bad rows directly. Here we show a sample explanation.
            if total_orphan > 0:
                st.warning(f"Found {total_orphan} orders referencing non-existent customers (Referential Integrity).")
            if total_negative > 0:
                st.error(f"Found {total_negative} orders with negative total amounts (Domain Error).")
            if total_duplicate > 0:
                st.error(f"Found {total_duplicate} duplicate orders (Uniqueness Violation).")
            if total_future > 0:
                st.info(f"Found {total_future} orders with future dates (Time Travel / Temporal Validity).")
            if total_math > 0:
                st.warning(f"Found {total_math} orders where Total != Price * Qty (Calculation Integrity).")
            if total_bad_status > 0:
                st.warning(f"Found {total_bad_status} orders with invalid status strings (Consistency / Dirty Data).")

if __name__ == "__main__":
    main()
